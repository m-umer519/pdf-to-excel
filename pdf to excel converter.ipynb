{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKlY7tUrGE5u",
        "outputId": "2a227dbc-25bd-4b7a-e09b-840764a76017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
          ]
        }
      ],
      "source": [
        "pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Path to your PDF file\n",
        "pdf_path = \"/your file.pdf\"  # Adjust to your file path\n",
        "\n",
        "# List to hold all data rows\n",
        "all_data = []\n",
        "headers = None\n",
        "\n",
        "# Open the PDF and process pages starting from page 2\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    total_pages = len(pdf.pages)\n",
        "    for page_num in range(1, total_pages):  # Page numbers start at 0, so 1 = page 2\n",
        "        page = pdf.pages[page_num]\n",
        "        # Extract tables from the page\n",
        "        tables = page.extract_tables()\n",
        "\n",
        "        for table in tables:\n",
        "            if not table:\n",
        "                continue\n",
        "\n",
        "            # Convert table to DataFrame\n",
        "            df = pd.DataFrame(table)\n",
        "\n",
        "            # Remove unwanted text rows\n",
        "            unwanted_phrases = [\n",
        "                r\"Page \\d+ of \\d+\",  # Matches \"Page X of Y\"\n",
        "                \"This is a system generated statement issued through Mashreq Online\"\n",
        "            ]\n",
        "            for phrase in unwanted_phrases:\n",
        "                df = df[~df.apply(lambda row: any(re.search(phrase, str(cell)) for cell in row), axis=1)]\n",
        "\n",
        "            if df.empty:\n",
        "                continue\n",
        "\n",
        "            # Extract headers from the first table (page 2)\n",
        "            if headers is None:\n",
        "                # Assume first two rows are headers, combine them\n",
        "                headers = df.iloc[0:2].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=0).tolist()\n",
        "                data = df.iloc[2:]  # Data starts after headers\n",
        "                if not data.empty:\n",
        "                    all_data.append(data)\n",
        "            else:\n",
        "                # Check if this table has headers repeated\n",
        "                potential_headers = df.iloc[0:2].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=0).tolist()\n",
        "                if potential_headers == headers:\n",
        "                    data = df.iloc[2:]  # Skip headers\n",
        "                    if not data.empty:\n",
        "                        all_data.append(data)\n",
        "                else:\n",
        "                    # Assume entire table is data if headers don’t match\n",
        "                    all_data.append(df)\n",
        "\n",
        "# Combine all data into one DataFrame\n",
        "if all_data:\n",
        "    final_df = pd.concat(all_data, ignore_index=True)\n",
        "    final_df.columns = headers\n",
        "\n",
        "    # Ensure numeric columns remain as strings to preserve decimals\n",
        "    # No conversion to float, keep as raw strings\n",
        "    # If you need to verify, uncomment below to see raw values\n",
        "    # print(final_df[['Amount لمبلغ', 'Balance الرصيد']].head())\n",
        "\n",
        "    # Save to Excel without float formatting to preserve original strings\n",
        "    final_df.to_excel(\"output_file.xlsx\", index=False, engine='openpyxl')\n",
        "    print(\"Data saved to output_file.xlsx with original decimal precision\")\n",
        "\n",
        "    # Save to CSV without float formatting\n",
        "    final_df.to_csv(\"output_file.csv\", index=False)\n",
        "    print(\"Data saved to output_file.csv with original decimal precision\")\n",
        "else:\n",
        "    print(\"No tables found after cleaning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhIX6DHBGz4l",
        "outputId": "2250639d-cb5b-49e2-e611-22bf1aea206f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to output_file.xlsx with original decimal precision\n",
            "Data saved to output_file.csv with original decimal precision\n"
          ]
        }
      ]
    }
  ]
}
